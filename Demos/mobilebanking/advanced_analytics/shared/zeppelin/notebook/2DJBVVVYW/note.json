{
  "paragraphs": [
    {
      "text": "%md\n# Prepare and Creating The Model\n\nAs with the TipType determination of taxi rides in the Big Data Analytics Learn exercises, this financial fraud challenge can also be viewed as a classification exercise for machine learning. Deciding what algorithm is best for your approach will depend on two things: the data analysis you have done thus far, and the line of inquiry you would like to pursue. You can review the supported algorithms and their features in the \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003eSpark ML Guide\u003c/a\u003e.\n\nBelow you will see one approach to creating a predictive model. Keep in mind that this page and its samples are not a learning module; rather, they present a challenge in this Play module, so the code is only given to you as an example. It is up to you to determine if the approach is valid, or if items were forgotten or unaddressed. Your method of solving this challenge will most likely differ based on how you would like to approach it. \n\nRemember that you are encouraged to share ideas with your peers via the **InterSystems Developer Community** to discuss approaches and solutions for this Play experience. \u003ca href\u003d\"https://community.intersystems.com/group/intersystems-iris-experience/\" target\u003d\"_blank\"\u003eThe InterSystems IRIS Experience group\u003c/a\u003e has been specially created for the InterSystems IRIS Experience. Be sure to tag your post with **Big Data Experience** to link up with other people in the Big Data Analytics Experience.\n",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003ePrepare and Creating The Model\u003c/h1\u003e\n\u003cp\u003eAs with the TipType determination of taxi rides in the Big Data Analytics Learn exercises, this financial fraud challenge can also be viewed as a classification exercise for machine learning. Deciding what algorithm is best for your approach will depend on two things: the data analysis you have done thus far, and the line of inquiry you would like to pursue. You can review the supported algorithms and their features in the \u003ca href\u003d\"https://spark.apache.org/docs/latest/ml-guide.html\" target\u003d\"_blank\"\u003eSpark ML Guide\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eBelow you will see one approach to creating a predictive model. Keep in mind that this page and its samples are not a learning module; rather, they present a challenge in this Play module, so the code is only given to you as an example. It is up to you to determine if the approach is valid, or if items were forgotten or unaddressed. Your method of solving this challenge will most likely differ based on how you would like to approach it. \u003c/p\u003e\n\u003cp\u003eRemember that you are encouraged to share ideas with your peers via the \u003cstrong\u003eInterSystems Developer Community\u003c/strong\u003e to discuss approaches and solutions for this Play experience. \u003ca href\u003d\"https://community.intersystems.com/group/intersystems-iris-experience/\" target\u003d\"_blank\"\u003eThe InterSystems IRIS Experience group\u003c/a\u003e has been specially created for the InterSystems IRIS Experience. Be sure to tag your post with \u003cstrong\u003eBig Data Experience\u003c/strong\u003e to link up with other people in the Big Data Analytics Experience.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1532538705171_2077900033",
      "id": "20170720-112641_833385781",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Feature Engineering\n\nIn previous notebooks, you saw how a number of fields seemed to have an interesting correlation with the `isFraud` column you are trying to predict. You can recap and add all of these fields to a dataset to present to the ML algorithms, or only the fields that you think are useful. ",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eFeature Engineering\u003c/h2\u003e\n\u003cp\u003eIn previous notebooks, you saw how a number of fields seemed to have an interesting correlation with the \u003ccode\u003eisFraud\u003c/code\u003e column you are trying to predict. You can recap and add all of these fields to a dataset to present to the ML algorithms, or only the fields that you think are useful.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1532538705172_2075976288",
      "id": "20180112-123939_1060016457",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "import com.intersystems.spark._\nval df \u003d spark.read.iris(\"zeppelin.PayTrans\")\n                .withColumn(\"hourOfDay\", $\"step\" % 24)\n                .withColumn(\"errorBalanceDest\", $\"oldBalanceDest\" + $\"amount\" - $\"newBalanceDest\")\n                .withColumn(\"errorBalanceOrig\", $\"oldBalanceOrig\" + $\"amount\" - $\"newBalanceOrig\")\n                \nval Array(training, test) \u003d df.randomSplit(Array(0.8, 0.2))",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": false,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Expression_1",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "Aggregate_2",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1532538705172_2075976288",
      "id": "20170720-110830_52791649",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "import org.apache.spark.ml.feature.RFormula\n\nval formula \u003d new RFormula()\n        .setFormula(\"isFraud ~ hourOfDay + errorBalanceDest + errorBalanceOrig + newbalanceDest + newbalanceOrig + oldbalanceDest + oldbalanceOrig + amount + transType\")",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": false,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Expression_1",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "Aggregate_2",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1532538705172_2075976288",
      "id": "20180123-183445_24217402",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Training and Testing the Model\n\nBelow you will see one approach to creating and testing a predictive model. You may find it useful, or you may choose to look at the data in a different way. \n ",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": false,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eTraining and Testing the Model\u003c/h2\u003e\n\u003cp\u003eBelow you will see one approach to creating and testing a predictive model. You may find it useful, or you may choose to look at the data in a different way.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1532538705173_2075591539",
      "id": "20180112-134158_544385219",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "import org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.classification.RandomForestClassifier\n\nval rf \u003d new RandomForestClassifier().setNumTrees(10)\nval pipeline \u003d new Pipeline().setStages(Array(formula, rf))\nval model \u003d pipeline.fit(training)",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": false,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Expression_1",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "Aggregate_2",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1532538705173_2075591539",
      "id": "20180123-183754_1840753278",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "import org.apache.spark.ml.classification.RandomForestClassificationModel\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n\nval predictions \u003d model.transform(test)\n\n// Select example rows to display.\npredictions.select(\"prediction\", \"label\", \"features\").show(5)\n\n// Select (prediction, true label) and compute test error.\nval evaluator \u003d new MulticlassClassificationEvaluator()\n  .setMetricName(\"accuracy\")\nval accuracy \u003d evaluator.evaluate(predictions)\nprintln(\"Test Error \u003d \" + (1.0 - accuracy))\n\nval rfModel \u003d model.stages(1).asInstanceOf[RandomForestClassificationModel]\nprintln(\"Learned classification forest model:\\n\" + rfModel.toDebugString)",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": false,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Expression_1",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "Aggregate_2",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1532538705173_2075591539",
      "id": "20180123-183915_1780363519",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "import org.apache.spark.ml.evaluation._\nimport org.apache.spark.mllib.evaluation._\n\n// to get access to more detailed metrics\nval metrics \u003d new MulticlassMetrics(predictions.rdd.map(row \u003d\u003e (row.getAs[Double](\"prediction\"), row.getAs[Double](\"label\"))))\n\nval labels \u003d metrics.labels\nlabels.foreach { l \u003d\u003e\n  println(s\"Class $l: Precision: \" + metrics.precision(l) + \"   /    Recall: \" + metrics.recall(l))\n}",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": false,
        "results": {
          "0": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "multiBarChart": {
                  "stacked": false
                }
              },
              "commonSetting": {},
              "keys": [
                {
                  "name": "Expression_1",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "values": [
                {
                  "name": "Aggregate_2",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ]
            },
            "helium": {}
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1532538705174_2076745786",
      "id": "20180123-184006_1502866717",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## Continuing On...\n\nWhat do you think of this example model and its results? Is it convincing? What may have been forgotten? Feel free to share your model, ideas, and experiences with your peers and InterSystems staff via the **InterSystems Developer Community** to discuss approaches and solutions. \u003ca href\u003d\"https://community.intersystems.com/group/intersystems-iris-experience/\" target\u003d\"_blank\"\u003eThe InterSystems IRIS Experience group\u003c/a\u003e has been specially created for the InterSystems IRIS Experience. Be sure to tag your post with **Big Data Experience** to link up with other people in the Big Data Analytics Experience.\n\nIs there a dataset or data challenge that you would like to work with in future Play experiences? You can also post these suggestions in the Developer Community. \n\nFinally, if you would like to find out more about how you could bring your organization\u0027s data and its challenges to InterSystems, use the \u003ca href\u003d\"https://www.intersystems.com/intersystems-iris-experience-followup/\" target\u003d\"_blank\"\u003eBuild phase\u003c/a\u003e of this Experience to talk to InterSystems about your project.\n\n",
      "dateUpdated": "Jul 25, 2018 5:11:45 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eContinuing On\u0026hellip;\u003c/h2\u003e\n\u003cp\u003eWhat do you think of this example model and its results? Is it convincing? What may have been forgotten? Feel free to share your model, ideas, and experiences with your peers and InterSystems staff via the \u003cstrong\u003eInterSystems Developer Community\u003c/strong\u003e to discuss approaches and solutions. \u003ca href\u003d\"https://community.intersystems.com/group/intersystems-iris-experience/\" target\u003d\"_blank\"\u003eThe InterSystems IRIS Experience group\u003c/a\u003e has been specially created for the InterSystems IRIS Experience. Be sure to tag your post with \u003cstrong\u003eBig Data Experience\u003c/strong\u003e to link up with other people in the Big Data Analytics Experience.\u003c/p\u003e\n\u003cp\u003eIs there a dataset or data challenge that you would like to work with in future Play experiences? You can also post these suggestions in the Developer Community. \u003c/p\u003e\n\u003cp\u003eFinally, if you would like to find out more about how you could bring your organization\u0026rsquo;s data and its challenges to InterSystems, use the \u003ca href\u003d\"https://www.intersystems.com/intersystems-iris-experience-followup/\" target\u003d\"_blank\"\u003eBuild phase\u003c/a\u003e of this Experience to talk to InterSystems about your project.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1532538705174_2076745786",
      "id": "20170720-160254_1256360401",
      "dateCreated": "Jul 25, 2018 5:11:45 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "3. Create and Test the Model",
  "id": "2DJBVVVYW",
  "angularObjects": {
    "2DHWQ7A7V:shared_process": [],
    "2DGTFGFBC:shared_process": [],
    "2DHATZD9M:shared_process": [],
    "2DKDARDPF:shared_process": [],
    "2DG8A819A:shared_process": [],
    "2DJVV28U3:shared_process": [],
    "2DKCAA3TS:shared_process": [],
    "2DHEPV9M3:shared_process": [],
    "2DKW8P766:shared_process": [],
    "2DGHX224C:shared_process": [],
    "2DGRSNE7G:shared_process": [],
    "2DGUG4SEP:shared_process": [],
    "2DHM86BYR:shared_process": [],
    "2DHYW1ZN6:shared_process": [],
    "2DJ16C4UE:shared_process": [],
    "2DJ4VH5DW:shared_process": [],
    "2DJBEDGYM:shared_process": [],
    "2DM19CFTF:shared_process": [],
    "2DHHCF91E:shared_process": [],
    "2DKCPR9P1:shared_process": []
  },
  "config": {},
  "info": {}
}